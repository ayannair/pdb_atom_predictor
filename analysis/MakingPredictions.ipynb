{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354a957e",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4689ab0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This notebook shows how to use a model to predict missing residues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e86c5",
   "metadata": {},
   "source": [
    "We begin by setting up the model classes. They have to match what we defined during machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ModelFC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelFC, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.fc_1 = nn.Linear(30,256)\n",
    "        self.fc_2 = nn.Linear(256,256)\n",
    "        self.fc_3 = nn.Linear(256, 64)         \n",
    "        self.fc_f = nn.Linear(64, 3)           \n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        x = x.reshape(len(x),-1)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        x = F.relu(self.fc_3(x))\n",
    "        x = self.fc_f(x)         \n",
    "        return x\n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            \n",
    "class Model1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(480,256)\n",
    "        self.fc_2 = nn.Linear(256,64)\n",
    "        self.fc_f = nn.Linear(64, 3)           \n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        x = self.conv_1(x)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        x = self.fc_f(x)       \n",
    "        #print(x.size())\n",
    "        return x\n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            \n",
    "class Model1D3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D3, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(640,256)\n",
    "        self.fc_2 = nn.Linear(256,64)\n",
    "        self.fc_f = nn.Linear(64, 3)           \n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        x = self.conv_1(x)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        x = self.fc_f(x)       \n",
    "        #print(x.size())\n",
    "        return x\n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            \n",
    "class Model1D3_ca_n_co_cb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D3_ca_n_co_cb, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(640,128)\n",
    "        self.fc_2 = nn.Linear(128,32)\n",
    "        self.fc_f = nn.Linear(32, 3)\n",
    "\n",
    "        self.cn_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcn_1 = nn.Linear(704,128)\n",
    "        self.fcn_2 = nn.Linear(128,32)\n",
    "        self.fcn_f = nn.Linear(32, 3)\n",
    "        \n",
    "        self.cco_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcco_1 = nn.Linear(768,128)\n",
    "        self.fcco_2 = nn.Linear(128,32)\n",
    "        self.fcco_f = nn.Linear(32, 6)\n",
    "\n",
    "        self.ccb_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fccb_1 = nn.Linear(896,128)\n",
    "        self.fccb_2 = nn.Linear(128,32)\n",
    "        self.fccb_f = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        xinp=x\n",
    "        x = self.conv_1(xinp)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        ca = self.fc_f(x)       \n",
    "       \n",
    "        car=ca.reshape(-1,3,1)\n",
    "        x = torch.cat((car,xinp),2)\n",
    "        x = self.cn_1(x)\n",
    "        x = F.relu(self.cn_2(x))\n",
    "        x = F.relu(self.cn_3(x))\n",
    "        x = F.relu(self.cn_4(x))\n",
    "        x = F.relu(self.cn_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fcn_1(x))\n",
    "        x = F.relu(self.fcn_2(x)) \n",
    "        n = self.fcn_f(x)       \n",
    "        \n",
    "        nr=n.reshape(-1,3,1)\n",
    "        x = torch.cat((car,nr,xinp),2)\n",
    "        x = self.cco_1(x)\n",
    "        x = F.relu(self.cco_2(x))\n",
    "        x = F.relu(self.cco_3(x))\n",
    "        x = F.relu(self.cco_4(x))\n",
    "        x = F.relu(self.cco_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fcco_1(x))\n",
    "        x = F.relu(self.fcco_2(x)) \n",
    "        co = self.fcco_f(x)       \n",
    "        c = co[:,0:3]\n",
    "        ox = co[:,3:6]\n",
    "        \n",
    "        cr=c.reshape(-1,3,1)\n",
    "        oxr=ox.reshape(-1,3,1)\n",
    "        x = torch.cat((car,nr,cr,oxr,xinp),2)\n",
    "        x = self.ccb_1(x)\n",
    "        x = F.relu(self.ccb_2(x))\n",
    "        x = F.relu(self.ccb_3(x))\n",
    "        x = F.relu(self.ccb_4(x))\n",
    "        x = F.relu(self.ccb_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fccb_1(x))\n",
    "        x = F.relu(self.fccb_2(x)) \n",
    "        x = self.fccb_f(x)       \n",
    "               \n",
    "        x = torch.cat((ca,n,c,ox,x),1)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def86327",
   "metadata": {},
   "source": [
    "We define and load a model saved from the machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Model1D3()\n",
    "#model.load_state_dict(torch.load('../machinelearning/ca_predict.dict'))\n",
    "\n",
    "model = Model1D3_ca_n_co_cb()\n",
    "model.load_state_dict(torch.load(f'../machinelearning/LYS_1d3_ca_n_co_cb_predict_aa.dict'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d7a7",
   "metadata": {},
   "source": [
    "Let's use the model!\n",
    "\n",
    "In the example we take a PDB, select a chain and a residue, and pretend that we remove it.\n",
    "We will then check how accurately we can predict the missing atoms (for now just $C\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "\n",
    "def project(vector,midpoint,xloc,yloc,zloc):\n",
    "    vmid=vector-midpoint\n",
    "    return [np.dot(vmid,xloc), np.dot(vmid,yloc), np.dot(vmid,zloc)]\n",
    "\n",
    "# can be any PDB\n",
    "pdb_fn=\"4hhb.pdb\"\n",
    "pdb=md.load_pdb(pdb_fn)\n",
    "\n",
    "# select chain and residue to be \"removed\"\n",
    "# unfortunately, mdtraj does not support chain ID letters, need to use index\n",
    "# in this case, chainid 1 is chain B\n",
    "\n",
    "selectchain=1\n",
    "selectresidue=30\n",
    "\n",
    "# atoms from residue to be \"removed\"\n",
    "ca_remove_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue} and name CA\")\n",
    "ca_remove=pdb.xyz[0][ca_remove_inx][0]\n",
    "n_remove_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue} and name N\")\n",
    "n_remove=pdb.xyz[0][n_remove_inx][0]\n",
    "c_remove_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue} and name C\")\n",
    "c_remove=pdb.xyz[0][c_remove_inx][0]\n",
    "o_remove_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue} and name O\")\n",
    "o_remove=pdb.xyz[0][o_remove_inx][0]\n",
    "cb_remove_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue} and name CB\")\n",
    "cb_remove=pdb.xyz[0][cb_remove_inx][0]\n",
    "\n",
    "\n",
    "\n",
    "# atoms from rest of structure needed to make prediction \n",
    "ca_m1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue-1} and name CA\")\n",
    "ca_m2_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue-2} and name CA\")\n",
    "ca_p1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue+1} and name CA\")\n",
    "ca_p2_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue+2} and name CA\")\n",
    "\n",
    "c_m1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue-1} and name C\")\n",
    "o_m1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue-1} and name O\")\n",
    "n_m1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue-1} and name N\")\n",
    "\n",
    "c_p1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue+1} and name C\")\n",
    "o_p1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue+1} and name O\")\n",
    "n_p1_inx=pdb.topology.select(f\"chainid {selectchain} and residue {selectresidue+1} and name N\")\n",
    "\n",
    "ca_m1=pdb.xyz[0][ca_m1_inx][0]\n",
    "ca_m2=pdb.xyz[0][ca_m2_inx][0]\n",
    "ca_p1=pdb.xyz[0][ca_p1_inx][0]\n",
    "ca_p2=pdb.xyz[0][ca_p2_inx][0]\n",
    "\n",
    "c_m1=pdb.xyz[0][c_m1_inx][0]\n",
    "o_m1=pdb.xyz[0][o_m1_inx][0]\n",
    "n_m1=pdb.xyz[0][n_m1_inx][0]\n",
    "\n",
    "c_p1=pdb.xyz[0][c_p1_inx][0]\n",
    "o_p1=pdb.xyz[0][o_p1_inx][0]\n",
    "n_p1=pdb.xyz[0][n_p1_inx][0]\n",
    "\n",
    "# construct local coordinate system - must match generation of features\n",
    "m=0.5*(ca_m1+ca_p1)\n",
    "l1=ca_p1-ca_m1\n",
    "l2=(ca_m2-ca_m1)+(ca_p2-ca_p1)\n",
    "l3=np.cross(l1,l2)\n",
    "ol2=np.cross(l3,l1)\n",
    "\n",
    "xlocal=l1/np.linalg.norm(l1)\n",
    "ylocal=ol2/np.linalg.norm(ol2)\n",
    "zlocal=l3/np.linalg.norm(l3)\n",
    "\n",
    "# project atoms onto local coordinate system\n",
    "ca_m1_local=project(ca_m1,m,xlocal,ylocal,zlocal)\n",
    "ca_m2_local=project(ca_m2,m,xlocal,ylocal,zlocal)\n",
    "ca_p1_local=project(ca_p1,m,xlocal,ylocal,zlocal)\n",
    "ca_p2_local=project(ca_p2,m,xlocal,ylocal,zlocal)\n",
    "\n",
    "o_m1_local=project(o_m1,m,xlocal,ylocal,zlocal)\n",
    "o_p1_local=project(o_p1,m,xlocal,ylocal,zlocal)\n",
    "n_m1_local=project(n_m1,m,xlocal,ylocal,zlocal)\n",
    "n_p1_local=project(n_p1,m,xlocal,ylocal,zlocal)\n",
    "c_m1_local=project(c_m1,m,xlocal,ylocal,zlocal)\n",
    "c_p1_local=project(c_p1,m,xlocal,ylocal,zlocal)\n",
    "            \n",
    "# this is our input feature string in the original format\n",
    "input_feature=ca_m1_local+ca_m2_local+ca_p1_local+ca_p2_local+ \\\n",
    "    o_m1_local+o_p1_local+n_m1_local+n_p1_local+c_m1_local+c_p1_local\n",
    "#print(input_feature)\n",
    "\n",
    "# this is reshaped into x / y / z as expected by Model1D3\n",
    "inputxyz =input_feature[0::3]+input_feature[1::3]+input_feature[2::3]\n",
    "inputxyzdata=np.reshape(np.array(inputxyz),(1,3,-1))\n",
    "#print(inputxyzdata)\n",
    "\n",
    "# now we run the model\n",
    "input=torch.tensor(inputxyzdata.astype(np.float32))\n",
    "output = model(input)\n",
    "#print(output)\n",
    "\n",
    "ca_remove_local_model=np.array([output[0][0].item(), output[0][1].item(), output[0][2].item()])\n",
    "n_remove_local_model=np.array([output[0][3].item(), output[0][4].item(), output[0][5].item()])\n",
    "c_remove_local_model=np.array([output[0][6].item(), output[0][7].item(), output[0][8].item()])\n",
    "o_remove_local_model=np.array([output[0][9].item(), output[0][10].item(), output[0][11].item()])\n",
    "cb_remove_local_model=np.array([output[0][12].item(), output[0][13].item(), output[0][14].item()])\n",
    "\n",
    "#print(ca_remove_local_model)\n",
    "\n",
    "# compare with projection of actual atom\n",
    "ca_remove_local=project(ca_remove,m,xlocal,ylocal,zlocal)\n",
    "#print(ca_remove_local)\n",
    "\n",
    "# converting local prediction back to Cartesian coordinates in original PDB frame\n",
    "ca_predict=ca_remove_local_model[0]*xlocal + ca_remove_local_model[1]*ylocal + ca_remove_local_model[2]*zlocal + m\n",
    "n_predict=n_remove_local_model[0]*xlocal + n_remove_local_model[1]*ylocal + n_remove_local_model[2]*zlocal + m\n",
    "c_predict=c_remove_local_model[0]*xlocal + c_remove_local_model[1]*ylocal + c_remove_local_model[2]*zlocal + m\n",
    "o_predict=o_remove_local_model[0]*xlocal + o_remove_local_model[1]*ylocal + o_remove_local_model[2]*zlocal + m\n",
    "cb_predict=cb_remove_local_model[0]*xlocal + cb_remove_local_model[1]*ylocal + cb_remove_local_model[2]*zlocal + m\n",
    "\n",
    "print(f\"removed Calpha with coordinates: {ca_remove}\")\n",
    "print(f\"prediction: {ca_predict}\")\n",
    "\n",
    "print(f\"removed N with coordinates: {n_remove}\")\n",
    "print(f\"prediction: {n_predict}\")\n",
    "\n",
    "print(f\"removed C with coordinates: {c_remove}\")\n",
    "print(f\"prediction: {c_predict}\")\n",
    "\n",
    "print(f\"removed O with coordinates: {o_remove}\")\n",
    "print(f\"prediction: {o_predict}\")\n",
    "\n",
    "print(f\"removed Cbeta with coordinates: {cb_remove}\")\n",
    "print(f\"prediction: {cb_predict}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import nglview as nv\n",
    "\n",
    "#pdb_fn=\"4hhb.pdb\"\n",
    "#pdb=md.load_pdb(pdb_fn)\n",
    "#selectresidue=30\n",
    "\n",
    "ratom=pdb.topology.atom(ca_remove_inx[0])\n",
    "top=md.Topology()\n",
    "newchain=top.add_chain()\n",
    "newres=top.add_residue(ratom.residue.name,newchain)\n",
    "newatom=top.add_atom(\"CA\",ratom.element,newres)\n",
    "newatom=top.add_atom(\"N\",ratom.element,newres)\n",
    "newatom=top.add_atom(\"C\",ratom.element,newres)\n",
    "newatom=top.add_atom(\"O\",ratom.element,newres)\n",
    "newatom=top.add_atom(\"CB\",ratom.element,newres)\n",
    "\n",
    "xyz=[ca_predict]\n",
    "xyz.append(n_predict)\n",
    "xyz.append(c_predict)\n",
    "xyz.append(o_predict)\n",
    "xyz.append(cb_predict)\n",
    "\n",
    "model=md.Trajectory(xyz,top)\n",
    "\n",
    "view = nv.NGLWidget(nv.MDTrajTrajectory(pdb))\n",
    "view.clear_representations()\n",
    "#view.add_cartoon('protein',color=\"grey\")\n",
    "view.add_licorice(':B',color=\"blue\")\n",
    "view.add_licorice(f'{selectresidue}:B',color=\"green\")\n",
    "view.add_spacefill(f'{selectresidue}:B and .CA', radius=\"0.5\", color=\"red\")\n",
    "\n",
    "view.add_trajectory(nv.MDTrajTrajectory(model))\n",
    "view[1].add_spacefill(radius=\"0.5\", color=\"orange\")\n",
    "\n",
    "view[0].center(f'{selectresidue}:B and .CA')\n",
    "view.camera='orthographic'\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d805b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb4d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
