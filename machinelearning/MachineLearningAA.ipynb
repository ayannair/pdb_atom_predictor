{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354a957e",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4689ab0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This part will train additional networks to predict other atoms and learn more specifically how to predict different amino acid residues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e86c5",
   "metadata": {},
   "source": [
    "We begin with some initial classes and functions to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "# optional parameters allow target data to be shifted and scaled\n",
    "    def __init__(self, target, data):\n",
    "        self.label = target.astype(np.float32)\n",
    "# assumes that data is prepared in correct shape beforehand\n",
    "        self.input = data\n",
    "    def __len__(self):\n",
    "        return self.label.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index].astype(np.float32), self.label[index]\n",
    "    \n",
    "def randomsplitdata(target_input_fn,training_fraction,maxrows=-1,select=\"CACNO\",aa='all'):\n",
    "    f=open(target_input_fn)\n",
    "    lsplit=f.readline().split()\n",
    "    f.close()\n",
    "\n",
    "    if (maxrows>0):\n",
    "        df=pd.read_csv(target_input_fn,sep=' ',header=None,nrows=maxrows)\n",
    "    else:\n",
    "        df=pd.read_csv(target_input_fn,sep=' ',header=None)\n",
    "        \n",
    "    if (aa == 'all'):\n",
    "        dfaa=df\n",
    "    else:\n",
    "        aalist=aa.split(':')\n",
    "        dfaa=df.loc[df[0].isin(aalist)]\n",
    "       \n",
    "    if (select == \"CACNO\"): \n",
    "        dft=dfaa[[*range(1,13)]]                                                 #ca, c, n, o\n",
    "    elif (select == \"CANCO\"):\n",
    "        dft=dfaa[[*range(1,4)]+[*range(7,10)]+[*range(4,7)]+[*range(10,13)]]     #ca, n, c, o\n",
    "    elif (select == \"CAN\"):\n",
    "        dft=dfaa[[*range(1,4)]+[*range(7,10)]]                                   #ca, n\n",
    "    elif (select == \"CAC\"):\n",
    "        dft=dfaa[[*range(1,7)]]                                                  #ca, c\n",
    "    elif (select == \"CACN\"):\n",
    "        dft=dfaa[[*range(1,10)]]                                                 #ca, c, n\n",
    "    elif (select == \"CA\"):\n",
    "        dft=dfaa[[*range(1,4)]]\n",
    "    else:\n",
    "        print('unknown selection')\n",
    "        sys.exit(1)\n",
    "      \n",
    "    targetdata=dft.to_numpy()\n",
    "    \n",
    "    print(targetdata.shape)\n",
    "\n",
    "    dfi=dfaa[[*range(len(lsplit)-30,len(lsplit))]]\n",
    "    inputdata=np.reshape(dfi.to_numpy(),(len(dfi),1,-1))\n",
    "      \n",
    "    xlist=[*range(len(lsplit)-30,len(lsplit),3)]\n",
    "    ylist=[*range(len(lsplit)-30+1,len(lsplit),3)]\n",
    "    zlist=[*range(len(lsplit)-30+2,len(lsplit),3)]\n",
    "    \n",
    "    dfixyz=dfi[xlist+ylist+zlist]\n",
    "    inpxyzdata=np.reshape(dfixyz.to_numpy(),(len(dfi),3,-1)) \n",
    "    \n",
    "    flag=np.zeros(len(targetdata),dtype=int)\n",
    "    while np.average(flag)<training_fraction:\n",
    "        flag[random.randint(0,len(targetdata)-1)]=1\n",
    "    \n",
    "    target_training=targetdata[np.nonzero(flag)].copy()\n",
    "    target_validation=targetdata[np.nonzero(1-flag)].copy()\n",
    "    input_training=inputdata[np.nonzero(flag)].copy()\n",
    "    input_validation=inputdata[np.nonzero(1-flag)].copy()\n",
    "    inputxyz_training=inpxyzdata[np.nonzero(flag)].copy()\n",
    "    inputxyz_validation=inpxyzdata[np.nonzero(1-flag)].copy()\n",
    "        \n",
    "    return target_training,input_training,inputxyz_training, \\\n",
    "           target_validation,input_validation,inputxyz_validation\n",
    "\n",
    "def get_loaders(target_input_fn,training_fraction,batch_size=128,maxrows=-1,aa='all',select=\"CACNO\"):\n",
    "    [ttarget,tinput,tinpxyz,vtarget,vinput,vinpxyz]=\\\n",
    "        randomsplitdata(target_input_fn,training_fraction,maxrows=maxrows,aa=aa,select=select) \n",
    "    \n",
    "    train_set=Dataset(ttarget,tinput)\n",
    "    validation_set=Dataset(vtarget,vinput)\n",
    "    trainxyz_set=Dataset(ttarget,tinpxyz)\n",
    "    valixyz_set=Dataset(vtarget,vinpxyz)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=1)\n",
    "    \n",
    "    trainxyz_loader = torch.utils.data.DataLoader(trainxyz_set, batch_size=batch_size, shuffle=True)\n",
    "    valixyz_loader = torch.utils.data.DataLoader(valixyz_set, batch_size=1)\n",
    "    \n",
    "    return train_loader,validation_loader,trainxyz_loader,valixyz_loader        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93f287",
   "metadata": {},
   "source": [
    "We set up training functions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(m,loss_fn,opt,loader,xscale=1.0,klfactor=0.0,klindex=0):\n",
    "    klloss=nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    loss_sum = 0.0\n",
    "    for input, label in loader:\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        output = m(input)               # this is where the model is evaluated\n",
    "        \n",
    "        loss =  loss_fn(output, label)  # model loss for x       \n",
    "        \n",
    "        if (xscale>1.0000001 or xscale<0.9999999):\n",
    "            nval=output.size(dim=1)\n",
    "            for n in (range(0,nval,3)):\n",
    "                loss += loss_fn(output[:,n], label[:,n])*(xscale-1.0)\n",
    "        \n",
    "        loss_sum += loss.item()         # accumulate MSE loss\n",
    "            \n",
    "        if (klfactor>0):\n",
    "            loss=loss+klfactor*\\\n",
    "                klloss(output[:,klindex],label[:,klindex])\n",
    "            \n",
    "        loss.backward()                 # this calculates the back-propagated loss\n",
    "        opt.step()                      # this carries out the gradient descent\n",
    "    \n",
    "    return loss_sum / len(loader)       # Note: KL loss is not included in reported loss\n",
    "\n",
    "def validate(m,loss_fn,loader,xscale=1.0):\n",
    "    loss_sum = 0.0\n",
    "    for input, label in loader:\n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        if (xscale>1.0000001 or xscale<0.9999999):\n",
    "            nval=output.size(dim=1)\n",
    "            for n in (range(0,nval,3)):\n",
    "                loss += loss_fn(output[:,n], label[:,n])*(xscale-1.0)\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / len(loader)\n",
    "\n",
    "def do_training(m,opt,tloader,vloader,epochs,output,xscale=1.0,klfactor=0.0,klindex=0):\n",
    "    # use MSE loss fucntion\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    tloss=np.zeros(epochs)\n",
    "    vloss=np.zeros(epochs)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        tloss[i] = train(m,loss_fn,opt,tloader,xscale,klfactor,klindex)\n",
    "        vloss[i] = validate(m,loss_fn,vloader,xscale)\n",
    "        if (output):\n",
    "            print (i, tloss[i], vloss[i])\n",
    "            \n",
    "    return tloss,vloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807f303",
   "metadata": {},
   "source": [
    "We also define some plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05dc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_progress(epochs,tloss,vloss):\n",
    "    plt.rcParams[\"figure.figsize\"]=(6,4)\n",
    "    epoch_index=np.arange(epochs)\n",
    "    plt.plot(epoch_index,np.log(tloss),color='r',label='training')\n",
    "    plt.plot(epoch_index,np.log(vloss),color='b',label='validation')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_validation(loader,m,inx=0):    \n",
    "    targetx=[]\n",
    "    targety=[]\n",
    "    targetz=[]\n",
    "    \n",
    "    predictionx=[]\n",
    "    predictiony=[]\n",
    "    predictionz=[]\n",
    "\n",
    "    for input, label in loader:        \n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "                 \n",
    "        targetx+=[label[0,inx*3+0].item()]\n",
    "        targety+=[label[0,inx*3+1].item()]\n",
    "        targetz+=[label[0,inx*3+2].item()]\n",
    "        \n",
    "        predictionx+=[output[0,inx*3+0].item()]\n",
    "        predictiony+=[output[0,inx*3+1].item()]\n",
    "        predictionz+=[output[0,inx*3+2].item()]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"]=(12,3)\n",
    "\n",
    "    fig,ax = plt.subplots(1,3)\n",
    "    \n",
    "    minval=np.min(targetx)\n",
    "    maxval=np.max(targetx)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "    \n",
    "    ax[0].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[0].plot(targetx,predictionx,'ro',markersize=2)\n",
    "    ax[0].set(xlabel='target x [nm]', ylabel=\"prediction [nm]\")\n",
    "    \n",
    "    minval=np.min(targety)\n",
    "    maxval=np.max(targety)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "\n",
    "    ax[1].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[1].plot(targety,predictiony,'ro',markersize=2)\n",
    "    ax[1].set(xlabel='target y [nm]', ylabel=\"\")\n",
    "\n",
    "    minval=np.min(targetz)\n",
    "    maxval=np.max(targetz)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "\n",
    "    ax[2].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[2].plot(targetz,predictionz,'ro',markersize=2)    \n",
    "    ax[2].set(xlabel='target z [nm]', ylabel=\"\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def linear_regression_output(x,y,txt):\n",
    "    x=np.reshape(np.array(x),(-1,1))\n",
    "    y=np.reshape(np.array(y),(-1,1))\n",
    "    linmodel=LinearRegression().fit(x,y)\n",
    "    r2=linmodel.score(x,y)\n",
    "    mval=linmodel.coef_[0]\n",
    "    nval=linmodel.intercept_\n",
    "    print(f'{txt}: r2 {r2} slope {mval[0]} offset {nval[0]}')\n",
    "    \n",
    "def linear_regression(loader,m,inx=0):    \n",
    "    targetx=[]\n",
    "    targety=[]\n",
    "    targetz=[]\n",
    "    \n",
    "    predictionx=[]\n",
    "    predictiony=[]\n",
    "    predictionz=[]\n",
    "\n",
    "    for input, label in loader:        \n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "                 \n",
    "        targetx+=[label[0,inx*3+0].item()]\n",
    "        targety+=[label[0,inx*3+1].item()]\n",
    "        targetz+=[label[0,inx*3+2].item()]\n",
    "        \n",
    "        predictionx+=[output[0,inx*3+0].item()]\n",
    "        predictiony+=[output[0,inx*3+1].item()]\n",
    "        predictionz+=[output[0,inx*3+2].item()]\n",
    "    \n",
    "    linear_regression_output(targetx,predictionx,\"x\")\n",
    "    linear_regression_output(targety,predictiony,\"y\")\n",
    "    linear_regression_output(targetz,predictionz,\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484abb0f",
   "metadata": {},
   "source": [
    "Next we define the neural network models\n",
    "\n",
    "Model1D3_ca_n extends Model1D3 to first predict CA using the previously trained weights and then to predict N using CA as input as well.\n",
    "\n",
    "Model1D3_ca_n_co extends Model1D3_ca_n to first predict CA, then N, and then C/O atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ce085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F          \n",
    "    \n",
    "class Model1D3_ca_n(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D3_ca_n, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(640,128)\n",
    "        self.fc_2 = nn.Linear(128,32)\n",
    "        self.fc_f = nn.Linear(32, 3)\n",
    "\n",
    "        self.cn_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcn_1 = nn.Linear(704,128)\n",
    "        self.fcn_2 = nn.Linear(128,32)\n",
    "        self.fcn_f = nn.Linear(32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        xinp=x\n",
    "        x = self.conv_1(xinp)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        ca = self.fc_f(x)       \n",
    "       \n",
    "        car=ca.reshape(-1,3,1)\n",
    "        # concatenate CA prediction with input features so that it can be \n",
    "        # used for prediction of N\n",
    "        x = torch.cat((car,xinp),2)\n",
    "        x = self.cn_1(x)\n",
    "        x = F.relu(self.cn_2(x))\n",
    "        x = F.relu(self.cn_3(x))\n",
    "        x = F.relu(self.cn_4(x))\n",
    "        x = F.relu(self.cn_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fcn_1(x))\n",
    "        x = F.relu(self.fcn_2(x)) \n",
    "        x = self.fcn_f(x)       \n",
    "        \n",
    "        # prediction is only for N, concatenate with CA for final output\n",
    "        x = torch.cat((ca,x),1)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "class Model1D3_ca_n_co(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D3_ca_n_co, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(640,128)\n",
    "        self.fc_2 = nn.Linear(128,32)\n",
    "        self.fc_f = nn.Linear(32, 3)\n",
    "\n",
    "        self.cn_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcn_1 = nn.Linear(704,128)\n",
    "        self.fcn_2 = nn.Linear(128,32)\n",
    "        self.fcn_f = nn.Linear(32, 3)\n",
    "        \n",
    "        self.cco_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcco_1 = nn.Linear(768,128)\n",
    "        self.fcco_2 = nn.Linear(128,32)\n",
    "        self.fcco_f = nn.Linear(32, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        xinp=x\n",
    "        x = self.conv_1(xinp)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        ca = self.fc_f(x)       \n",
    "       \n",
    "        car=ca.reshape(-1,3,1)\n",
    "        x = torch.cat((car,xinp),2)\n",
    "        x = self.cn_1(x)\n",
    "        x = F.relu(self.cn_2(x))\n",
    "        x = F.relu(self.cn_3(x))\n",
    "        x = F.relu(self.cn_4(x))\n",
    "        x = F.relu(self.cn_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fcn_1(x))\n",
    "        x = F.relu(self.fcn_2(x)) \n",
    "        n = self.fcn_f(x)       \n",
    "        \n",
    "        nr=n.reshape(-1,3,1)\n",
    "        x = torch.cat((car,nr,xinp),2)\n",
    "        x = self.cco_1(x)\n",
    "        x = F.relu(self.cco_2(x))\n",
    "        x = F.relu(self.cco_3(x))\n",
    "        x = F.relu(self.cco_4(x))\n",
    "        x = F.relu(self.cco_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fcco_1(x))\n",
    "        x = F.relu(self.fcco_2(x)) \n",
    "        x = self.fcco_f(x)       \n",
    "        \n",
    "        x = torch.cat((ca,n,x),1)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4eb241",
   "metadata": {},
   "source": [
    "Now we are training the models. \n",
    "\n",
    "First we train Model1D3_ca_n using weights from the previously trained C-alpha model.\n",
    "\n",
    "We begin by using only data from proline residues because they have a larger fraction of cis backbone conformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde48a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PRO'\n",
    "\n",
    "# load data for CA-N atoms for proline residues only\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CAN\") \n",
    "\n",
    "# initialize model\n",
    "m = Model1D3_ca_n()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load('ca_1d3_predict_3.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts N \n",
    "# this means that the CA prediction is not changed during training\n",
    "for param in m.cn_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cn_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cn_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cn_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cn_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fcn_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fcn_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fcn_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "# extra options focus training on x coordinates of N atoms (klindex=3)\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=10.0,klfactor=2.0,klindex=3)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_predict.dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4fb35",
   "metadata": {},
   "source": [
    "We now extend training using more amino acids, reduced learning rate, and slightly less emphasis on x coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4eb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa='PRO:ALA:VAL:LEU'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CAN\") \n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=1.0,klindex=3)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_predict.dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa17de",
   "metadata": {},
   "source": [
    "One more round with lower learning rate, reduced emphasis on x coordinates, and additional amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4eff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa='PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CAN\") \n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0001, weight_decay=0.000001)\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0,klfactor=1.0,klindex=3)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_predict.dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755e48e",
   "metadata": {},
   "source": [
    "We now use the trained CA-N model and add predictions of C/O atoms.\n",
    "\n",
    "We start with proline and alanine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6dda9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PRO:ALA:VAL'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_predict.dict'),strict=False)\n",
    "\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in m.cco_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cco_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cco_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cco_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.cco_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fcco_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fcco_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fcco_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001, weight_decay=0.00001)\n",
    "\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=1.0,klindex=6)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict.dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be04ae",
   "metadata": {},
   "source": [
    "We continue training with more amino acids and lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96069019",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa='PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0,klfactor=0.8,klindex=6)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict.dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fb6f2",
   "metadata": {},
   "source": [
    "Let's now further train separate models for individual amino acids. \n",
    "\n",
    "In these models, all weights are allowed to change to obtain optimal models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a6cdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ALA'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e13ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='VAL'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618da483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='LEU'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff95158",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ASP'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1d1cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='GLN'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148323fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='GLU'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13635c28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='TRP'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8e51d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='SER'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e52ca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='THR'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4736a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ASN'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc83287",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='TYR'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44515bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='HIS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13292df0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='CYS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b19f85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='MET'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74f73b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='GLY'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a6404",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PHE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e3bfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='LYS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42786fb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ARG'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262f76b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ILE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb78d3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PRO'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCO\") \n",
    "\n",
    "m = Model1D3_ca_n_co()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "m.load_state_dict(torch.load('PRO:ALA:VAL:LEU:ASP:SER:LYS:PHE_1d3_ca_n_co_predict.dict'),strict=False)\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(),lr=0.0002, weight_decay=0.000001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=2.0)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fa10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
