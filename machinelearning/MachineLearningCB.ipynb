{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354a957e",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4689ab0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This part will train additional networks to predict C-beta positions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e86c5",
   "metadata": {},
   "source": [
    "We begin with some initial classes and functions to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "# optional parameters allow target data to be shifted and scaled\n",
    "    def __init__(self, target, data):\n",
    "        self.label = target.astype(np.float32)\n",
    "# assumes that data is prepared in correct shape beforehand\n",
    "        self.input = data\n",
    "    def __len__(self):\n",
    "        return self.label.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index].astype(np.float32), self.label[index]\n",
    "    \n",
    "def randomsplitdata(target_input_fn,training_fraction,maxrows=-1,select=\"CACNO\",aa='all'):\n",
    "    f=open(target_input_fn)\n",
    "    lsplit=f.readline().split()\n",
    "    f.close()\n",
    "\n",
    "    if (maxrows>0):\n",
    "        df=pd.read_csv(target_input_fn,sep=' ',header=None,nrows=maxrows)\n",
    "    else:\n",
    "        df=pd.read_csv(target_input_fn,sep=' ',header=None)\n",
    "        \n",
    "    if (aa == 'all'):\n",
    "        dfaa=df\n",
    "    else:\n",
    "        aalist=aa.split(':')\n",
    "        dfaa=df.loc[df[0].isin(aalist)]\n",
    "       \n",
    "    if (select == \"CACNO\"): \n",
    "        dft=dfaa[[*range(1,13)]]                                                 #ca, c, n, o\n",
    "    elif (select == \"CANCO\"):\n",
    "        dft=dfaa[[*range(1,4)]+[*range(7,10)]+[*range(4,7)]+[*range(10,13)]]     #ca, n, c, o\n",
    "    elif (select == \"CAN\"):\n",
    "        dft=dfaa[[*range(1,4)]+[*range(7,10)]]                                   #ca, n\n",
    "    elif (select == \"CAC\"):\n",
    "        dft=dfaa[[*range(1,7)]]                                                  #ca, c\n",
    "    elif (select == \"CACN\"):\n",
    "        dft=dfaa[[*range(1,10)]]                                                 #ca, c, n\n",
    "    elif (select == \"CA\"):\n",
    "        dft=dfaa[[*range(1,4)]]\n",
    "    elif (select == \"CACNOCB\"):\n",
    "        dft=dfaa[[*range(1,16)]]\n",
    "    elif (select == \"CANCOCB\"):\n",
    "        dft=dfaa[[*range(1,4)]+[*range(7,10)]+[*range(4,7)]+[*range(10,16)]]     #ca, n, c, o\n",
    "    else:\n",
    "        print('unknown selection')\n",
    "        sys.exit(1)\n",
    "      \n",
    "    targetdata=dft.to_numpy()\n",
    "    \n",
    "    print(targetdata.shape)\n",
    "\n",
    "    dfi=dfaa[[*range(len(lsplit)-30,len(lsplit))]]\n",
    "    inputdata=np.reshape(dfi.to_numpy(),(len(dfi),1,-1))\n",
    "      \n",
    "    xlist=[*range(len(lsplit)-30,len(lsplit),3)]\n",
    "    ylist=[*range(len(lsplit)-30+1,len(lsplit),3)]\n",
    "    zlist=[*range(len(lsplit)-30+2,len(lsplit),3)]\n",
    "    \n",
    "    dfixyz=dfi[xlist+ylist+zlist]\n",
    "    inpxyzdata=np.reshape(dfixyz.to_numpy(),(len(dfi),3,-1)) \n",
    "    \n",
    "    flag=np.zeros(len(targetdata),dtype=int)\n",
    "    while np.average(flag)<training_fraction:\n",
    "        flag[random.randint(0,len(targetdata)-1)]=1\n",
    "    \n",
    "    target_training=targetdata[np.nonzero(flag)].copy()\n",
    "    target_validation=targetdata[np.nonzero(1-flag)].copy()\n",
    "    input_training=inputdata[np.nonzero(flag)].copy()\n",
    "    input_validation=inputdata[np.nonzero(1-flag)].copy()\n",
    "    inputxyz_training=inpxyzdata[np.nonzero(flag)].copy()\n",
    "    inputxyz_validation=inpxyzdata[np.nonzero(1-flag)].copy()\n",
    "        \n",
    "    return target_training,input_training,inputxyz_training, \\\n",
    "           target_validation,input_validation,inputxyz_validation\n",
    "\n",
    "def get_loaders(target_input_fn,training_fraction,batch_size=128,maxrows=-1,aa='all',select=\"CACNO\"):\n",
    "    [ttarget,tinput,tinpxyz,vtarget,vinput,vinpxyz]=\\\n",
    "        randomsplitdata(target_input_fn,training_fraction,maxrows=maxrows,aa=aa,select=select) \n",
    "    \n",
    "    train_set=Dataset(ttarget,tinput)\n",
    "    validation_set=Dataset(vtarget,vinput)\n",
    "    trainxyz_set=Dataset(ttarget,tinpxyz)\n",
    "    valixyz_set=Dataset(vtarget,vinpxyz)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=1)\n",
    "    \n",
    "    trainxyz_loader = torch.utils.data.DataLoader(trainxyz_set, batch_size=batch_size, shuffle=True)\n",
    "    valixyz_loader = torch.utils.data.DataLoader(valixyz_set, batch_size=1)\n",
    "    \n",
    "    return train_loader,validation_loader,trainxyz_loader,valixyz_loader        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93f287",
   "metadata": {},
   "source": [
    "We set up training functions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(m,loss_fn,opt,loader,xscale=1.0,klfactor=0.0,klindex=0):\n",
    "    klloss=nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    loss_sum = 0.0\n",
    "    for input, label in loader:\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        output = m(input)               # this is where the model is evaluated\n",
    "        \n",
    "        loss =  loss_fn(output, label)  # model loss for x       \n",
    "        \n",
    "        if (xscale>1.0000001 or xscale<0.9999999):\n",
    "            nval=output.size(dim=1)\n",
    "            for n in (range(0,nval,3)):\n",
    "                loss += loss_fn(output[:,n], label[:,n])*(xscale-1.0)\n",
    "        \n",
    "        loss_sum += loss.item()         # accumulate MSE loss\n",
    "            \n",
    "        if (klfactor>0):\n",
    "            loss=loss+klfactor*\\\n",
    "                klloss(output[:,klindex],label[:,klindex])\n",
    "            \n",
    "        loss.backward()                 # this calculates the back-propagated loss\n",
    "        opt.step()                      # this carries out the gradient descent\n",
    "    \n",
    "    return loss_sum / len(loader)       # Note: KL loss is not included in reported loss\n",
    "\n",
    "def validate(m,loss_fn,loader,xscale=1.0):\n",
    "    loss_sum = 0.0\n",
    "    for input, label in loader:\n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        if (xscale>1.0000001 or xscale<0.9999999):\n",
    "            nval=output.size(dim=1)\n",
    "            for n in (range(0,nval,3)):\n",
    "                loss += loss_fn(output[:,n], label[:,n])*(xscale-1.0)\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / len(loader)\n",
    "\n",
    "def do_training(m,opt,tloader,vloader,epochs,output,xscale=1.0,klfactor=0.0,klindex=0):\n",
    "    # use MSE loss fucntion\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    tloss=np.zeros(epochs)\n",
    "    vloss=np.zeros(epochs)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        tloss[i] = train(m,loss_fn,opt,tloader,xscale,klfactor,klindex)\n",
    "        vloss[i] = validate(m,loss_fn,vloader,xscale)\n",
    "        if (output):\n",
    "            print (i, tloss[i], vloss[i])\n",
    "            \n",
    "    return tloss,vloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807f303",
   "metadata": {},
   "source": [
    "We also define some plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05dc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_progress(epochs,tloss,vloss):\n",
    "    plt.rcParams[\"figure.figsize\"]=(6,4)\n",
    "    epoch_index=np.arange(epochs)\n",
    "    plt.plot(epoch_index,np.log(tloss),color='r',label='training')\n",
    "    plt.plot(epoch_index,np.log(vloss),color='b',label='validation')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_validation(loader,m,inx=0):    \n",
    "    targetx=[]\n",
    "    targety=[]\n",
    "    targetz=[]\n",
    "    \n",
    "    predictionx=[]\n",
    "    predictiony=[]\n",
    "    predictionz=[]\n",
    "\n",
    "    for input, label in loader:        \n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "                 \n",
    "        targetx+=[label[0,inx*3+0].item()]\n",
    "        targety+=[label[0,inx*3+1].item()]\n",
    "        targetz+=[label[0,inx*3+2].item()]\n",
    "        \n",
    "        predictionx+=[output[0,inx*3+0].item()]\n",
    "        predictiony+=[output[0,inx*3+1].item()]\n",
    "        predictionz+=[output[0,inx*3+2].item()]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"]=(12,3)\n",
    "\n",
    "    fig,ax = plt.subplots(1,3)\n",
    "    \n",
    "    minval=np.min(targetx)\n",
    "    maxval=np.max(targetx)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "    \n",
    "    ax[0].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[0].plot(targetx,predictionx,'ro',markersize=2)\n",
    "    ax[0].set(xlabel='target x [nm]', ylabel=\"prediction [nm]\")\n",
    "    \n",
    "    minval=np.min(targety)\n",
    "    maxval=np.max(targety)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "\n",
    "    ax[1].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[1].plot(targety,predictiony,'ro',markersize=2)\n",
    "    ax[1].set(xlabel='target y [nm]', ylabel=\"\")\n",
    "\n",
    "    minval=np.min(targetz)\n",
    "    maxval=np.max(targetz)\n",
    "    lin=np.linspace(minval-0.1*(maxval-minval),maxval+0.1*(maxval-minval),num=100)\n",
    "\n",
    "    ax[2].plot(lin,lin,'k',linewidth=2)\n",
    "    ax[2].plot(targetz,predictionz,'ro',markersize=2)    \n",
    "    ax[2].set(xlabel='target z [nm]', ylabel=\"\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def linear_regression_output(x,y,txt):\n",
    "    x=np.reshape(np.array(x),(-1,1))\n",
    "    y=np.reshape(np.array(y),(-1,1))\n",
    "    linmodel=LinearRegression().fit(x,y)\n",
    "    r2=linmodel.score(x,y)\n",
    "    mval=linmodel.coef_[0]\n",
    "    nval=linmodel.intercept_\n",
    "    print(f'{txt}: r2 {r2} slope {mval[0]} offset {nval[0]}')\n",
    "    \n",
    "def linear_regression(loader,m,inx=0):    \n",
    "    targetx=[]\n",
    "    targety=[]\n",
    "    targetz=[]\n",
    "    \n",
    "    predictionx=[]\n",
    "    predictiony=[]\n",
    "    predictionz=[]\n",
    "\n",
    "    for input, label in loader:        \n",
    "        with torch.no_grad():\n",
    "            output = m(input)\n",
    "                 \n",
    "        targetx+=[label[0,inx*3+0].item()]\n",
    "        targety+=[label[0,inx*3+1].item()]\n",
    "        targetz+=[label[0,inx*3+2].item()]\n",
    "        \n",
    "        predictionx+=[output[0,inx*3+0].item()]\n",
    "        predictiony+=[output[0,inx*3+1].item()]\n",
    "        predictionz+=[output[0,inx*3+2].item()]\n",
    "    \n",
    "    linear_regression_output(targetx,predictionx,\"x\")\n",
    "    linear_regression_output(targety,predictiony,\"y\")\n",
    "    linear_regression_output(targetz,predictionz,\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484abb0f",
   "metadata": {},
   "source": [
    "Next we define the neural network models\n",
    "\n",
    "Model1D3_ca_n_co_cb extends Model1D3_ca_n_co_cb to first predict CA,N,C/O using previously trained weights and then to predict CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ce085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F          \n",
    "    \n",
    "class Model1D3_ca_n_co_cb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1D3_ca_n_co_cb, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # dimensional flattening\n",
    "        self.flatten = nn.Flatten(start_dim=1) \n",
    "        # fully connected layers\n",
    "        self.fc_1 = nn.Linear(640,128)\n",
    "        self.fc_2 = nn.Linear(128,32)\n",
    "        self.fc_f = nn.Linear(32, 3)\n",
    "\n",
    "        self.cn_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cn_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcn_1 = nn.Linear(704,128)\n",
    "        self.fcn_2 = nn.Linear(128,32)\n",
    "        self.fcn_f = nn.Linear(32, 3)\n",
    "        \n",
    "        self.cco_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.cco_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fcco_1 = nn.Linear(768,128)\n",
    "        self.fcco_2 = nn.Linear(128,32)\n",
    "        self.fcco_f = nn.Linear(32, 6)\n",
    "\n",
    "        self.ccb_1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_4 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.ccb_f = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # fully connected layers\n",
    "        self.fccb_1 = nn.Linear(896,128)\n",
    "        self.fccb_2 = nn.Linear(128,32)\n",
    "        self.fccb_f = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # back-propagation is done automatically\n",
    "        xinp=x\n",
    "        x = self.conv_1(xinp)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.relu(self.conv_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x)) \n",
    "        ca = self.fc_f(x)       \n",
    "       \n",
    "        car=ca.reshape(-1,3,1)\n",
    "        x = torch.cat((car,xinp),2)\n",
    "        x = self.cn_1(x)\n",
    "        x = F.relu(self.cn_2(x))\n",
    "        x = F.relu(self.cn_3(x))\n",
    "        x = F.relu(self.cn_4(x))\n",
    "        x = F.relu(self.cn_f(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fcn_1(x))\n",
    "        x = F.relu(self.fcn_2(x)) \n",
    "        n = self.fcn_f(x)       \n",
    "        \n",
    "        nr=n.reshape(-1,3,1)\n",
    "        x = torch.cat((car,nr,xinp),2)\n",
    "        x = self.cco_1(x)\n",
    "        x = F.relu(self.cco_2(x))\n",
    "        x = F.relu(self.cco_3(x))\n",
    "        x = F.relu(self.cco_4(x))\n",
    "        x = F.relu(self.cco_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fcco_1(x))\n",
    "        x = F.relu(self.fcco_2(x)) \n",
    "        co = self.fcco_f(x)       \n",
    "        c = co[:,0:3]\n",
    "        ox = co[:,3:6]\n",
    "        \n",
    "        cr=c.reshape(-1,3,1)\n",
    "        oxr=ox.reshape(-1,3,1)\n",
    "        x = torch.cat((car,nr,cr,oxr,xinp),2)\n",
    "        x = self.ccb_1(x)\n",
    "        x = F.relu(self.ccb_2(x))\n",
    "        x = F.relu(self.ccb_3(x))\n",
    "        x = F.relu(self.ccb_4(x))\n",
    "        x = F.relu(self.ccb_f(x))\n",
    "        x = self.flatten(x)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fccb_1(x))\n",
    "        x = F.relu(self.fccb_2(x)) \n",
    "        x = self.fccb_f(x)       \n",
    "               \n",
    "        x = torch.cat((ca,n,c,ox,x),1)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self, m):\n",
    "        # initialization of weights, setting them to zero is not good\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4eb241",
   "metadata": {},
   "source": [
    "Now we are training the models using the pretrained weights for specific amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde48a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ALA'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=1.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8cc59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PRO'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=1.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7a2f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='VAL'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa3b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='LEU'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63a97c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='PHE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fd02a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ILE'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=10\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e9e82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='TYR'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289135f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='TRP'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d96ed5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ASP'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b59e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='ASN'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4b567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='GLU'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdc8db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='GLN'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=3.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8eef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='TYR'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f27e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='CYS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=30\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dfd15a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa='HIS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d443bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='LYS'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "#m.load_state_dict(torch.load(f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\"))\n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "\n",
    "epochs=20\n",
    "#epochs=5\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30efa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='MET'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601357f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='SER'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae35712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa='THR'\n",
    "\n",
    "[tloader,vloader,txyzloader,vxyzloader]=\\\n",
    "    get_loaders('../generatingfeatures/longer_local_i_aa_capm2opmnpmcpm.dat',0.8,\\\n",
    "               batch_size=512,aa=aa,select=\"CANCOCB\") \n",
    "\n",
    "m = Model1D3_ca_n_co_cb()\n",
    "m.apply(m.initialize_weights)\n",
    "m.zero_grad()\n",
    "\n",
    "# load partial weights from previous model\n",
    "# may use other models previously trained \n",
    "m.load_state_dict(torch.load(f'{aa}_1d3_ca_n_co_predict_aa.dict'),strict=False)\n",
    "\n",
    "# disable training of all weights\n",
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# reenable training of only the second part of the network that predicts Cbetas \n",
    "# this means that the CA/N/CO prediction is not changed during training\n",
    "for param in m.ccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.ccb_f.parameters():\n",
    "    param.requires_grad = True   \n",
    "for param in m.fccb_1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in m.fccb_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer with extra options to only train certain weights\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005, weight_decay=0.00001)\n",
    "\n",
    "epochs=20\n",
    "showoutput=True\n",
    "\n",
    "[tloss,vloss]=do_training(m,opt,txyzloader,vxyzloader,epochs,showoutput,xscale=5.0,klfactor=2.0,klindex=12)\n",
    "\n",
    "plot_progress(epochs,tloss,vloss)\n",
    "\n",
    "print('CA')\n",
    "plot_validation(vxyzloader,m,0)\n",
    "linear_regression(vxyzloader,m,0)\n",
    "\n",
    "print('N')\n",
    "plot_validation(vxyzloader,m,1)\n",
    "linear_regression(vxyzloader,m,1)\n",
    "\n",
    "print('C')\n",
    "plot_validation(vxyzloader,m,2)\n",
    "linear_regression(vxyzloader,m,2)\n",
    "\n",
    "print('O')\n",
    "plot_validation(vxyzloader,m,3)\n",
    "linear_regression(vxyzloader,m,3)\n",
    "\n",
    "print('CB')\n",
    "plot_validation(vxyzloader,m,4)\n",
    "linear_regression(vxyzloader,m,4)\n",
    "\n",
    "\n",
    "torch.save(m.state_dict(),f\"{aa}_1d3_ca_n_co_cb_predict_aa.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba385b3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
